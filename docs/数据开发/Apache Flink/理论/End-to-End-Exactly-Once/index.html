<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-数据开发/Apache Flink/理论/End-to-End-Exactly-Once">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">End-to-End-Exactly-Once | 大数据知识库</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://zhangyongtian.github.io/docs/数据开发/Apache Flink/理论/End-to-End-Exactly-Once"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="End-to-End-Exactly-Once | 大数据知识库"><meta data-rh="true" name="description" content="Flink 在1.4.0 版本引入『exactly-once』并号称支持『End-to-End Exactly-Once』“端到端的精确一次”语义。"><meta data-rh="true" property="og:description" content="Flink 在1.4.0 版本引入『exactly-once』并号称支持『End-to-End Exactly-Once』“端到端的精确一次”语义。"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://zhangyongtian.github.io/docs/数据开发/Apache Flink/理论/End-to-End-Exactly-Once"><link data-rh="true" rel="alternate" href="https://zhangyongtian.github.io/docs/数据开发/Apache Flink/理论/End-to-End-Exactly-Once" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://zhangyongtian.github.io/en/docs/数据开发/Apache Flink/理论/End-to-End-Exactly-Once" hreflang="en-GB"><link data-rh="true" rel="alternate" href="https://zhangyongtian.github.io/docs/数据开发/Apache Flink/理论/End-to-End-Exactly-Once" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="大数据知识库 RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="大数据知识库 Atom Feed"><link rel="stylesheet" href="/assets/css/styles.c7c4384d.css">
<link rel="preload" href="/assets/js/runtime~main.4dcd1c4b.js" as="script">
<link rel="preload" href="/assets/js/main.d89d1304.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="BigdataKnowledge Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.svg" alt="BigdataKnowledge Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">BigdataKnowledge</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/概览">文档</a><a class="navbar__item navbar__link" href="/blog">博客</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/zhangyongtian/bigdataknowledge" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="切换浅色/暗黑模式（当前为浅色模式）" aria-label="切换浅色/暗黑模式（当前为浅色模式）" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="搜索" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/概览">概览</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/开发者指南">开发者指南</a><button aria-label="打开/收起侧边栏菜单「开发者指南」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/数仓理论">数仓理论</a><button aria-label="打开/收起侧边栏菜单「数仓理论」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/数据质量">数据质量</a><button aria-label="打开/收起侧边栏菜单「数据质量」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/数据集成">数据集成</a><button aria-label="打开/收起侧边栏菜单「数据集成」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/数据协调">数据协调</a><button aria-label="打开/收起侧边栏菜单「数据协调」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/数据调度">数据调度</a><button aria-label="打开/收起侧边栏菜单「数据调度」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/容器调度">容器调度</a><button aria-label="打开/收起侧边栏菜单「容器调度」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/数据存储">数据存储</a><button aria-label="打开/收起侧边栏菜单「数据存储」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/category/数据开发">数据开发</a><button aria-label="打开/收起侧边栏菜单「数据开发」" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/docs/category/apache-flink">Apache Flink</a><button aria-label="打开/收起侧边栏菜单「Apache Flink」" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/docs/category/理论">理论</a><button aria-label="打开/收起侧边栏菜单「理论」" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/数据开发/Apache Flink/理论/概览">概览</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/数据开发/Apache Flink/理论/Runtime核心机制">Runtime核心机制</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/数据开发/Apache Flink/理论/时间属性深度解析">时间属性深度解析</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/数据开发/Apache Flink/理论/Checkpoint 原理剖析与应用实战">Checkpoint 原理剖析与应用实战</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/数据开发/Apache Flink/理论/Flink 架构概览">Flink 架构概览</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/数据开发/Apache Flink/理论/数据类型和序列化">数据类型和序列化</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/数据开发/Apache Flink/理论/Flink 作业执行深度解析">Flink 作业执行深度解析</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/数据开发/Apache Flink/理论/网络流控及反压剖析">网络流控及反压剖析</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/数据开发/Apache Flink/理论/End-to-End-Exactly-Once">End-to-End-Exactly-Once</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/实践">实践</a><button aria-label="打开/收起侧边栏菜单「实践」" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/apache-paimon">Apache Paimon</a><button aria-label="打开/收起侧边栏菜单「Apache Paimon」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/apache-spark">Apache Spark</a><button aria-label="打开/收起侧边栏菜单「Apache Spark」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/apache-streampark">Apache StreamPark</a><button aria-label="打开/收起侧边栏菜单「Apache StreamPark」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/dinky">Dinky</a><button aria-label="打开/收起侧边栏菜单「Dinky」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/数据开发/概览">概览</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/平台监控">平台监控</a><button aria-label="打开/收起侧边栏菜单「平台监控」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/bi报表">BI报表</a><button aria-label="打开/收起侧边栏菜单「BI报表」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/自动化运维">自动化运维</a><button aria-label="打开/收起侧边栏菜单「自动化运维」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/项目实战案例">项目实战案例</a><button aria-label="打开/收起侧边栏菜单「项目实战案例」" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/faq">FAQ</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/comminicate">交流与贡献</a></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/数据开发"><span itemprop="name">数据开发</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/apache-flink"><span itemprop="name">Apache Flink</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/理论"><span itemprop="name">理论</span></a><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">End-to-End-Exactly-Once</span><meta itemprop="position" content="4"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>End-to-End-Exactly-Once</h1></header><p>Flink 在1.4.0 版本引入『exactly-once』并号称支持『End-to-End Exactly-Once』“端到端的精确一次”语义。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="流处理的数据处理语义">流处理的数据处理语义<a href="#流处理的数据处理语义" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h2><p>对于<strong>批处理，fault-tolerant（容错性）很容易做，失败只需要replay</strong>，就可以完美做到容错。
对于流处理，数据流本身是动态，没有所谓的开始或结束，<strong>虽然可以replay buffer的部分数据，但fault-tolerant做起来会复杂的多</strong>
流处理（有时称为事件处理）可以<strong>简单地描述为是对无界数据或事件的连续处理</strong>。流或事件处理应用程序可以或多或少地被描述为有向图，并且通常被描述为有向无环图（DAG）。在这样的图中，每个边表示数据或事件流，每个顶点表示运算符，会使用程序中定义的逻辑处理来自相邻边的数据或事件。<strong>有两种特殊类型的顶点，通常称为 sources 和 sinks</strong>。sources读取外部数据/事件到应用程序中，而 sinks 通常会收集应用程序生成的结果。下图是流式应用程序的示例。有如下特点：</p><ul><li><p>分布式情况下是由多个Source(读取数据)节点、多个Operator(数据处理)节点、多个Sink(输出)节点构成</p></li><li><p>每个节点的并行数可以有差异，且每个节点都有可能发生故障</p></li><li><p>对于数据正确性最重要的一点，就是当发生故障时，是怎样容错与恢复的。</p></li></ul><p><img loading="lazy" alt="flink的并行度" src="/assets/images/bingxingdu-48e38762c00e82d895bcf9f90faff092.svg" width="576" height="397" class="img_ev3q"></p><p>流处理引擎通常为应用程序提供了三种数据处理语义：最多一次、至少一次和精确一次。</p><p><strong>如下是对这些不同处理语义的宽松定义(一致性由弱到强)：</strong></p><ul><li>At most noce &lt; At least once &lt; Exactly once &lt; End to End Exactly once</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="at-most-once-最多一次">At-most-once 最多一次<a href="#at-most-once-最多一次" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>有可能会有数据丢失，这意味着如果数据在被流应用程序完全处理之前发生丢失，则不会进行其他重试或者重新发送。</p><p><img loading="lazy" alt="最多一次" src="/assets/images/at-most-once-0895f76109556cd442ae6c80a72b4f1d.png" width="945" height="175" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="at-least-once-至少一次">At-least-once 至少一次<a href="#at-least-once-至少一次" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>有可能重复处理数据，这通常意味着如果事件在流应用程序完全处理之前丢失，则将从源头重放或重新传输事件。然而，由于事件是可以被重传的，因此一个事件有时会被处理多次(至少一次)。</p><p><img loading="lazy" alt="至少一次" src="/assets/images/at-least-once-d56b361cd3209ba317a014c2a1bc5646.png" width="879" height="241" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="exactly-once-精确一次">Exactly-once 精确一次<a href="#exactly-once-精确一次" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>这种语义会保证每一条消息只被流处理系统处理一次。即使是在各种故障的情况下，流应用程序中的所有算子都保证事件只会被『精确一次』的处理。（也有文章将 Exactly-once 翻译为：完全一次，恰好一次）</p><p>Flink实现『精确一次』的分布式快照/状态检查点方法受到 Chandy-Lamport 分布式快照算法的启发。通过这种机制，流应用程序中每个算子的所有状态都会定期做 checkpoint。如果是在系统中的任何地方发生失败，每个算子的所有状态都回滚到最新的全局一致 checkpoint 点。在回滚期间，将暂停所有处理。源也会重置为与最近 checkpoint 相对应的正确偏移量。<strong>整个流应用程序基本上是回到最近一次的一致状态，然后程序可以从该状态重新启动</strong>。</p><p><img loading="lazy" alt="精确一次" src="/assets/images/exactly-once-5b7fce94f9319f6d0cfc936a912aec4e.png" width="859" height="770" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="end-to-end-exactly-once-端到端的精确一次">End-to-End Exactly-Once 端到端的精确一次<a href="#end-to-end-exactly-once-端到端的精确一次" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>Flink 在1.4.0 版本引入『exactly-once』并号称支持『End-to-End Exactly-Once』“端到端的精确一次”语义。</p><p>它指的是 Flink 应用从 Source 端开始到 Sink 端结束，数据必须经过的起始点和结束点。</p><p>注意：</p><p>『exactly-once』和『End-to-End Exactly-Once』的区别:</p><p><strong>简单来说，&quot;Exactly-once&quot;关注自己的数据处理，而&quot;End-to-End Exactly-Once&quot;关注整个数据处理链路的保证。</strong></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="精确一次-有效一次">精确一次? 有效一次!<a href="#精确一次-有效一次" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>有些人可能认为『精确一次』描述了事件处理的保证，其中流中的每个事件只被处理一次。实际上，没有引擎能够保证正好只处理一次。在面对任意故障时，<strong>不可能保证每个算子中的用户定义逻辑在每个事件中只执行一次，因为用户代码被部分执行的可能性是永远存在的</strong>。</p><p>那么，当引擎声明『精确一次』处理语义时，它们能保证什么呢？如果不能保证用户逻辑只执行一次，那么什么逻辑只执行一次？当引擎声明『精确一次』处理语义时，<strong>它们实际上是在说，它们可以保证引擎管理的状态更新只提交一次到持久的后端存储</strong>。</p><p><strong>事件的处理可以发生多次，但是该处理的效果只在持久后端状态存储中反映一次</strong>。因此，我们认为有效地描述这些处理语义最好的术语是『有效一次』（effectively once）</p><p><strong>流计算系统如何支持一致性语义</strong></p><ul><li><p>去重保证End-to-End Exactly-Once</p><p>  <img loading="lazy" alt="去重保证End-to-End Exactly-Once" src="/assets/images/yizhixing-d4a042524ec4cea975cb6355791561a2.png" width="817" height="401" class="img_ev3q"></p></li><li><p>分布式快照</p><p>  <img loading="lazy" alt="分布式快照" src="/assets/images/fenbushikuaiz-6dd4ec58ff310074fa2e13e1bc595f1b.png" width="833" height="429" class="img_ev3q"></p></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="end-to-end-exactly-once的实现">​​​​​​​End-to-End Exactly-Once的实现<a href="#end-to-end-exactly-once的实现" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h2><p>通过前面的学习，我们了解到，<strong>Flink内部借助分布式快照Checkpoint已经实现了内部的Exactly-Once</strong>，但是Flink 自身是无法保证外部其他系统“精确一次”语义的，所以 <strong>Flink 若要实现所谓“端到端（End to End）的精确一次”的要求，那么外部系统必须支持“精确一次”语义；</strong>然后借助一些其他手段才能实现。如下：</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="source">​​​​Source<a href="#source" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p><strong>发生故障时需要支持重设数据的读取位置</strong>，如Kafka可以通过offset来实现（其他的没有offset系统，我们可以自己实现累加器计数）</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="transformation">​​​​​​​Transformation<a href="#transformation" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>也就是Flink内部，已经通过Checkpoint保证了，如果发生故障或出错时，<strong>Flink应用重启后会从最新成功完成的checkpoint中恢复——重置应用状态并回滚状态到checkpoint中输入流的正确位置</strong>，之后再开始执行数据处理，就好像该故障或崩溃从未发生过一般。</p><ul><li><p>分布式快照机制</p><p>  我们在之前的课程中讲解过 Flink 的容错机制，Flink 提供了失败恢复的容错机制，而这个容错机制的核心就是持续创建分布式数据流的快照来实现。</p><p>  <img loading="lazy" alt="分布式快照" src="/assets/images/fenbushikuaiz2-02c6b2d1ac0564157d6ca140acfd2c46.png" width="864" height="505" class="img_ev3q"></p></li><li><p>Barrier</p><p>  Flink 分布式快照的核心元素之一是 Barrier（数据栅栏），我们也可以把 Barrier 简单地理解成一个标记，该标记是严格有序的，并且随着数据流往下流动，<strong>经过那个算子那么就会把对应算子的状态开始保存下来，如果出现错误恢复的时候，那么它就能够从最近一次保存的成功的地方恢复，如果Barrier经过的算子状态都保存成功，那么就会通知jobmanager这一次ck成功了</strong>。每个 Barrier 都带有自己的 ID，Barrier 极其轻量，并不会干扰正常的数据处理。</p><p>  <img loading="lazy" alt="分布式快照" src="/assets/images/barrier2-14db0f10ac96f24ec4e10142aa0b8eb8.avif" class="img_ev3q"></p><p>  具体过程如下，JobManager 向 SourceTask 发送 CheckPointTrigger，SourceTask 会在数据流中安插 CheckPoint barrier。</p><p>  <img loading="lazy" alt="分布式快照" src="/assets/images/bcao1-f63d7f3582e81280614470ef752154e4.avif" class="img_ev3q"></p><p>  Source Task 自身做快照，并保存到状态后端。</p><p>  <img loading="lazy" alt="分布式快照" src="/assets/images/bcao2-8cd3c7fd56414144a9f41bc461e1a9f9.avif" class="img_ev3q"></p><p>  Source Task 将 barrier 跟数据流一块往下游发送。</p><p>  <img loading="lazy" alt="分布式快照" src="/assets/images/bcap3-4fc5f7ca7bdd3543eec0aab72abf1c5a.avif" class="img_ev3q"></p><p>  当下游的 Operator 实例接收到 CheckPointbarrier 后，对自身做快照。</p><p>  <img loading="lazy" alt="分布式快照" src="/assets/images/bcao5-be5fd5db9fbb3d2b29db9dc98fb0bead.avif" class="img_ev3q"></p><p>  如下图，有 4 个带状态的 Operator 实例，相应的状态后端就可以想象成填 4 个格子。整个 CheckPoint 的过程可以当做 Operator 实例填自己格子的过程，Operator 实例将自身的状态写到状态后端中相应的格子，当所有的格子填满可以简单的认为一次完整的 CheckPoint 做完了。</p><p>  <img loading="lazy" alt="分布式快照" src="/assets/images/bcao6-51ab081fe886c2af84878a3e84f90d63.avif" class="img_ev3q"></p><p>  多 Operator 状态恢复</p><p>  <img loading="lazy" alt="分布式快照" src="/assets/images/bcao7-88ee4d59b8b093af70b7c56941448e07.avif" class="img_ev3q"></p></li><li><p>什么是 barrier 对齐？</p><p>  <img loading="lazy" alt="分布式快照" src="/assets/images/bcao8-64f6a29868835f64ae1288e00b638297.avif" class="img_ev3q"></p><p>  如上图，<strong>当一个 Operator 接收到 Checkpoint barrier n 时，它会暂停处理来自该输入流的任何数据记录，直到其他所有输入流也接收到 barrier n 为止</strong>。这样做是为了避免混合属于当前快照 n 和下一个快照 n + 1 的数据记录。在等待其他输入流都接收到 barrier n 后，Operator 会先处理缓冲区中的待处理数据记录，然后再继续处理所有输入流的数据记录。处理完成后，它会将 Checkpoint barrier n 继续传递给下游，并对自身进行快照，以保证数据处理的一致性和容错性。</p></li><li><p>什么是 barrier 不对齐？</p><p>  &quot;barrier 对齐&quot; 意味着当有其他输入流的 barrier 尚未到达时，Operator 会将已经到达的 barrier 之后的数据（例如1、2、3）搁置在缓冲区中，等待其他流的 barrier 到达后才一起处理。<strong>&quot;barrier 不对齐&quot; 意味着在处理过程中不需要等待所有输入流的 barrier 对齐，而可以直接处理已到达的 barrier 之后的数据。直到所有输入流的 barrier 齐全后，Operator 才会执行 Checkpoint 操作</strong>，对当前状态进行快照，以保证数据处理的一致性和容错性。这样的机制能够在不影响性能的情况下进行高效的流式处理。</p></li><li><p>为什么要进行 barrier 对齐？不对齐到底行不行？</p><p>  在实现 Exactly Once 语义时，必须保证 barrier 对齐，否则会降级为 At Least Once 语义。CheckPoint 的目的是为了保存状态快照，在不对齐的情况下，已经处理的快照之后的数据会在恢复任务后被再次处理，导致数据重复消费。</p></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sink">​​​​​​​Sink<a href="#sink" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>需要支持幂等写入或事务写入(Flink的两阶段提交需要事务支持)</p><ul><li><p>​​​​​​​幂等写入（Idempotent Writes）</p><p>  幂等写操作是指：任意多次向一个系统写入数据，只对目标系统产生一次结果影响。</p><p>  例如，重复向一个HashMap里插入同一个Key-Value二元对，第一次插入时这个HashMap发生变化，后续的插入操作不会改变HashMap的结果，这就是一个幂等写操作。</p></li><li><p>​​​​​​​事务写入（Transactional Writes）</p><p>  Flink借鉴了数据库中的事务处理技术，同时结合自身的Checkpoint机制来保证Sink只对外部输出产生一次影响。大致的流程如下:</p><p>  <strong>Flink先将待输出的数据保存下来暂时不向外部系统提交，等到Checkpoint结束时，Flink上下游所有算子的数据都是一致的时候，Flink将之前保存的数据全部提交（Commit）到外部系统</strong>。换句话说，只有经过Checkpoint确认的数据才向外部系统写入。</p><p>  如下图所示，如果使用事务写，那只把时间戳3之前的输出提交到外部系统，时间戳3以后的数据（例如时间戳5和8生成的数据）暂时保存下来，等待下次Checkpoint时一起写入到外部系统。这就避免了时间戳5这个数据产生多次结果，多次写入到外部系统，<strong>简单点说就是在写入外部系统之前先写入一个缓冲区，用户是不可见的，当Checkpoint成功以后那么数据对于用户才是可见的</strong>。</p><p>  <img loading="lazy" alt="两阶段提交" src="/assets/images/017fe4269663d628b2b5f14953f5e1c-b897c77e8407cf47f7e023ce76c87d41.png" width="871" height="536" class="img_ev3q"></p><ul><li><p>在事务写的具体实现上，Flink目前提供了两种方式：</p><ol><li><p>预写日志（Write-Ahead-Log，WAL）</p><p>WAL方式通用性更强，适合几乎所有外部系统。</p></li><li><p>如果外部系统自身就支持事务（比如MySQL、Kafka），可以使用2PC方式，可以提供百分百端到端的Exactly-Once</p><p>事务写的方式能提供端到端的Exactly-Once一致性，它的代价也是非常明显的，就是牺牲了延迟。输出数据不再是实时写入到外部系统，而是分批次地提交。目前来说，没有完美的故障恢复和Exactly-Once保障机制，对于开发者来说，需要在不同需求之间权衡。</p></li></ol></li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="flinkkafka的end-to-end-exactly-once">​​​​​​​Flink+Kafka的End-to-End Exactly-Once<a href="#flinkkafka的end-to-end-exactly-once" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="版本说明">版本说明<a href="#版本说明" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>Flink 1.4版本之前，支持Exactly Once语义，仅限于应用内部。Flink 1.4版本之后，通过两阶段提交(TwoPhaseCommitSinkFunction)支持End-To-End Exactly Once，而且要求Kafka 0.11+。利用TwoPhaseCommitSinkFunction是通用的管理方案，只要实现对应的接口，即可实现端到端的划一性语义。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="两阶段提交-api">​​​​​​​两阶段提交-API<a href="#两阶段提交-api" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>在 Flink 中的Two-Phase-Commit-2PC两阶段提交的实现方法被封装到了 TwoPhaseCommitSinkFunction 这个抽象类中，只需要实现其中的beginTransaction、preCommit、commit、abort 四个方法就可以实现“精确一次”的处理语义，如FlinkKafkaProducer就实现了该类并实现了这些方法。</p><ol><li><p>beginTransaction，在开启事务之前，我们在目标文件系统的临时目录中创建一个临时文件，后面在处理数据时将数据写入此文件。</p></li><li><p>preCommit，在预提交阶段，刷写（flush）文件，然后关闭文件，之后就不能写入到文件了，我们还将为属于下一个检查点的任何后续写入启动新事务。</p></li><li><p>commit，在提交阶段，我们将预提交的文件原子性移动到真正的目标目录中，请注意，这会增加输出数据可见性的延迟。</p></li><li><p>abort，在中止阶段，我们删除临时文件。</p></li></ol><h3 class="anchor anchorWithStickyNavbar_LWe7" id="两阶段提交-详细流程">​​​​​​​两阶段提交-详细流程<a href="#两阶段提交-详细流程" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>接下来将介绍两阶段提交协议，以及它如何在一个读写Kafka的Flink程序中实现端到端的Exactly-Once语义。Kafka经常与Flink一起使用，且Kafka在最近的0.11版本中添加了对事务的支持。这意味着现在通过Flink读写Kafaka，并提供端到端的Exactly-Once语义有了必要的支持。</p><p><img loading="lazy" alt="两阶段提交" src="/assets/images/70a2d32b81640d13d2af14261ee96c6-f7e8db5fedfbd19bc8cadfdefdc90f35.png" width="895" height="394" class="img_ev3q"></p><ul><li><p>预提交-内部状态</p><p>  在checkpoint开始的时候，即两阶段提交协议的“预提交”阶段。当checkpoint开始时，Flink的JobManager会将checkpoint barrier注入数据流。brarrier在operator之间传递。对于每一个operator，它触发operator的状态快照写入到state backend。</p><p>  <img loading="lazy" alt="两阶段提交,预提交内部状态" src="/assets/images/fb2ce5686f36d4a1605db2905cebb3f-6893157fabf2b0f7fe6bac29ae4692ba.png" width="876" height="394" class="img_ev3q"></p><p>  <strong>数据源保存了消费Kafka的偏移量(offset)，之后将checkpoint barrier传递给下一个operator。这种方式仅适用于operator具有『内部』状态。所谓内部状态，是指Flink state backend保存和管理的</strong> </p><p>  <img loading="lazy" alt="两阶段提交,预提交内部状态" src="/assets/images/2d606a6fde6b70a613a363397fdbbd5-b9fba55f5d3de3d2457e777ef5e4a766.png" width="883" height="475" class="img_ev3q"></p></li><li><p>预提交-外部状态</p><p>  但是，当进程具有『外部』状态时，需要作些额外的处理。外部状态通常以写入外部系统（如Kafka）的形式出现。在这种情况下，为了提供Exactly-Once保证，外部系统必须支持事务，这样才能和两阶段提交协议集成。</p><p>  在该示例中的数据需要写入Kafka，因此数据输出端（Data Sink）有外部状态。在这种情况下，在预提交阶段，<strong>除了将其状态写入state backend之外，数据输出端还必须预先提交其外部事务</strong>。</p><p>  <img loading="lazy" alt="两阶段提交,预提交外部状态" src="/assets/images/8ef2e82481cec2a685bd23068a517de-574139c5e6945af2a55963830f36849d.png" width="859" height="452" class="img_ev3q"></p><p>  <strong>当checkpoint barrier在所有operator都传递了一遍，并且触发的checkpoint回调成功完成时，预提交阶段就结束了</strong>。所有触发的状态快照都被视为该checkpoint的一部分。checkpoint是整个应用程序状态的快照，包括预先提交的外部状态。如果发生故障，我们可以回滚到上次成功完成快照的时间点。</p></li><li><p>提交阶段</p><p>  下一步是通知所有operator，checkpoint已经成功了。这是两阶段提交协议的提交阶段，JobManager为应用程序中的每个operator发出checkpoint已完成的回调。</p><p>  数据源和widnow operator没有外部状态，因此在提交阶段，这些operator不必执行任何操作。但是，数据输出端（Data Sink）拥有外部状态，此时应该提交外部事务。</p><p>  <img loading="lazy" alt="两阶段提交,预提交外部状态" src="/assets/images/2e5d28ccbbf4dca22a451d8e3d6978c-77ffccaaf75e8dcc656ce8a0b2966333.png" width="875" height="412" class="img_ev3q"></p></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="代码例子">代码例子<a href="#代码例子" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><div class="language-JAVA codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-JAVA codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">/**</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Desc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Kafka --&gt; Flink--&gt;Kafka  的End-To-End-Exactly-once</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * 直接使用</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * FlinkKafkaConsumer  +  Flink的Checkpoint  +  FlinkKafkaProducer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> */</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">public class Kafka_Flink_Kafka_EndToEnd_ExactlyOnce {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    public static void main(String[] args) throws Exception {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //1.env</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //===========Checkpoint参数设置====</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //===========类型1:必须参数=============</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //ck保存的地方可以设置在flink.conf里面</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //设置Checkpoint的时间间隔为1000ms做一次Checkpoint/其实就是每隔1000ms发一次Barrier!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        env.enableCheckpointing(1000);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //===========类型2:建议参数===========</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //设置两个Checkpoint 之间最少等待时间,如设置Checkpoint之间最少是要等 500ms(为了避免每隔1000ms做一次Checkpoint的时候,前一次太慢和后一次重叠到一起去了)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //如:高速公路上,每隔1s关口放行一辆车,但是规定了两车之前的最小车距为500m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        env.getCheckpointConfig().setMinPauseBetweenCheckpoints(500);//默认是0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //设置是否清理检查点,表示 Cancel 时是否需要保留当前的 Checkpoint，默认 Checkpoint会在作业被Cancel时被删除</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //ExternalizedCheckpointCleanup.DELETE_ON_CANCELLATION：true,当作业被取消时，删除外部的checkpoint(默认值)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION：false,当作业被取消时，保留外部的checkpoint</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //===========类型3:直接使用默认的即可===============</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //设置checkpoint的执行模式为EXACTLY_ONCE(默认)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //设置checkpoint的超时时间,如果 Checkpoint在 60s内尚未完成说明该次Checkpoint失败,则丢弃。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        env.getCheckpointConfig().setCheckpointTimeout(60000);//默认10分钟</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //设置同一时间有多少个checkpoint可以同时执行</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);//默认为1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //=============重启策略===========</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        env.setRestartStrategy(RestartStrategies.fixedDelayRestart(3, Time.of(10, TimeUnit.SECONDS)));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //2.Source</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Properties props_source = new Properties();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        props_source.setProperty(&quot;bootstrap.servers&quot;, &quot;node1:9092&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        props_source.setProperty(&quot;group.id&quot;, &quot;flink&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        props_source.setProperty(&quot;auto.offset.reset&quot;, &quot;latest&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        props_source.setProperty(&quot;flink.partition-discovery.interval-millis&quot;, &quot;5000&quot;);//会开启一个后台线程每隔5s检测一下Kafka的分区情况</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        FlinkKafkaConsumer&lt;String&gt; kafkaSource = new FlinkKafkaConsumer&lt;&gt;(&quot;flink_kafka&quot;, new SimpleStringSchema(), props_source);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //kafkaSource.setStartFromGroupOffsets();//设置从记录的offset开始消费,如果没有记录从auto.offset.reset配置开始消费</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //kafkaSource.setStartFromEarliest();//设置直接从Earliest消费,和auto.offset.reset配置无关</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        kafkaSource.setStartFromLatest();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        kafkaSource.setCommitOffsetsOnCheckpoints(true);//执行Checkpoint的时候提交offset到Checkpoint(Flink用),并且提交一份到默认主题:__consumer_offsets(外部其他系统想用的话也可以获取到)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        DataStreamSource&lt;String&gt; kafkaDS = env.addSource(kafkaSource);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //3.​​​​​​​Transformation ......</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //4.sink</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Properties properties = new Properties();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //在和kafka精确一次整合的时候，记得事务的超时时间要是检查点触发时间和超时时间之和才行不然会出错，还有就是，也就是事务超时的时间要大于ck的时间</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        properties.put(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG,CommonString.CHECKPOINT_TIMEOUT+CommonString.CHECKPOINT_TIME*2);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //properties.setProperty(ProducerConfig.LINGER_MS_CONFIG, &quot;2000&quot;); 不能使用默认值，不然事务运行会出错,因为用事务预提交的时候有一个缓冲过程</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        properties.setProperty(ProducerConfig.LINGER_MS_CONFIG, &quot;2000&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        KafkaSink sink = KafkaSink.&lt;String&gt;builder()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                .setBootstrapServers(kafka_servsers)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                .setRecordSerializer(CustomKafkaRecordSerializationSchema.buildCustomKafkaRecordSerializationSchema())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                .setDeliverGuarantee(DeliveryGuarantee.EXACTLY_ONCE)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                //设置事务前缀</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                .setTransactionalIdPrefix(kafka_transactionalIdprefix)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                .setKafkaProducerConfig(properties)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                .build();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        env</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                .fromSource(mySqlSource, WatermarkStrategy.noWatermarks(), &quot;CustomMySQL Source&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                .setParallelism(3).sinkTo(sink);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //5.execute</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        env.execute();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>详细代码细节查看官网</p><blockquote><p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/connectors/datastream/kafka/#fault-tolerance" target="_blank" rel="noopener noreferrer">https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/connectors/datastream/kafka/#fault-tolerance</a></p></blockquote><h3 class="anchor anchorWithStickyNavbar_LWe7" id="总结">总结<a href="#总结" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><ol><li><p>一旦所有operator完成预提交，就提交一个commit。</p></li><li><p>如果只要有一个预提交失败，则所有其他提交都将中止，我们将回滚到上一个成功完成的checkpoint。</p></li><li><p>在预提交成功之后，提交的commit需要保证最终成功 – operator和外部系统都需要保障这点。如果commit失败（例如，由于间歇性网络问题），整个Flink应用程序将失败，应用程序将根据用户的重启策略重新启动，还会尝试再提交。这个过程至关重要，因为如果commit最终没有成功，将会导致数据丢失。</p></li><li><p>完整的实现两阶段提交协议可能有点复杂，这就是为什么Flink将它的通用逻辑提取到抽象类TwoPhaseCommitSinkFunction中的原因。</p></li></ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/zhangyongtian/bigdataknowledge/tree/dev/docs/数据开发/Apache Flink/理论/End-to-End-Exactly-Once.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文档分页导航"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/数据开发/Apache Flink/理论/网络流控及反压剖析"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">网络流控及反压剖析</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/category/实践"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">实践</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#流处理的数据处理语义" class="table-of-contents__link toc-highlight">流处理的数据处理语义</a><ul><li><a href="#at-most-once-最多一次" class="table-of-contents__link toc-highlight">At-most-once 最多一次</a></li><li><a href="#at-least-once-至少一次" class="table-of-contents__link toc-highlight">At-least-once 至少一次</a></li><li><a href="#exactly-once-精确一次" class="table-of-contents__link toc-highlight">Exactly-once 精确一次</a></li><li><a href="#end-to-end-exactly-once-端到端的精确一次" class="table-of-contents__link toc-highlight">End-to-End Exactly-Once 端到端的精确一次</a></li><li><a href="#精确一次-有效一次" class="table-of-contents__link toc-highlight">精确一次? 有效一次!</a></li></ul></li><li><a href="#end-to-end-exactly-once的实现" class="table-of-contents__link toc-highlight">​​​​​​​End-to-End Exactly-Once的实现</a><ul><li><a href="#source" class="table-of-contents__link toc-highlight">​​​​Source</a></li><li><a href="#transformation" class="table-of-contents__link toc-highlight">​​​​​​​Transformation</a></li><li><a href="#sink" class="table-of-contents__link toc-highlight">​​​​​​​Sink</a></li></ul></li><li><a href="#flinkkafka的end-to-end-exactly-once" class="table-of-contents__link toc-highlight">​​​​​​​Flink+Kafka的End-to-End Exactly-Once</a><ul><li><a href="#版本说明" class="table-of-contents__link toc-highlight">版本说明</a></li><li><a href="#两阶段提交-api" class="table-of-contents__link toc-highlight">​​​​​​​两阶段提交-API</a></li><li><a href="#两阶段提交-详细流程" class="table-of-contents__link toc-highlight">​​​​​​​两阶段提交-详细流程</a></li><li><a href="#代码例子" class="table-of-contents__link toc-highlight">代码例子</a></li><li><a href="#总结" class="table-of-contents__link toc-highlight">总结</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">文档</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/概览">文档</a></li></ul></div><div class="col footer__col"><div class="footer__title">社区</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/zhangyongtian/bigdataknowledge" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github Discussion<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">更多</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">博客</a></li><li class="footer__item"><a href="https://github.com/zhangyongtian/bigdataknowledge" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Issues<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.4dcd1c4b.js"></script>
<script src="/assets/js/main.d89d1304.js"></script>
</body>
</html>